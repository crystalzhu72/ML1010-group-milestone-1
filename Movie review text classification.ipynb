{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "collect-simpson",
   "metadata": {},
   "source": [
    "# Import raw data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nuclear-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "agricultural-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fatal-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "earned-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path=r\"C:\\Users\\yunan\\Downloads\\York U\\Machine Learning Cert\\ML1010\\aclImdb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accessible-studio",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read train pos files\n",
    "text=[]\n",
    "file_names=[]\n",
    "is_positive=[]\n",
    "#path=r\"C:\\Users\\yunan\\Downloads\\York U\\Machine Learning Cert\\ML1010\\aclImdb\\train\\neg\"\n",
    "#filenames=glob.glob(path + \"/*.txt\")\n",
    "with os.scandir(r\"C:\\Users\\yunan\\Downloads\\York U\\Machine Learning Cert\\ML1010\\Group project 1\\aclImdb\\train\\pos\") as filenames:\n",
    "    for file in filenames:\n",
    "        head, tail = os.path.split(file)\n",
    "        file_names.append(tail)\n",
    "        is_positive.append(1)\n",
    "        with open(file, 'rb') as open_file:\n",
    "            text.append(open_file.readlines()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "competent-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.DataFrame({'file':file_names, 'text':text, 'is_positive':is_positive})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "floral-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read train neg files\n",
    "with os.scandir(r\"C:\\Users\\yunan\\Downloads\\York U\\Machine Learning Cert\\ML1010\\Group project 1\\aclImdb\\train\\neg\") as filenames:\n",
    "    for file in filenames:\n",
    "        head,tail=os.path.split(file)\n",
    "        file_names.append(tail)\n",
    "        is_positive.append(0)\n",
    "        with open(file,'rb') as open_file:\n",
    "            text.append(open_file.readlines()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ruled-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.DataFrame({'file':file_names, 'text':text, 'is_positive':is_positive})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "corresponding-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text']=train_df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "racial-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dataset size - select only 5000 records\n",
    "positive_reviews = train_df[:2500]   #take first 2500 reviews which are positive\n",
    "negative_reviews = train_df[22500:]  #last last 2500 reviews which are negative\n",
    "new_train = positive_reviews.append(negative_reviews, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adjacent-intention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_9.txt</td>\n",
       "      <td>b'Bromwell High is a cartoon comedy. It ran at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000_8.txt</td>\n",
       "      <td>b'Homelessness (or Houselessness as George Car...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001_10.txt</td>\n",
       "      <td>b'Brilliant over-acting by Lesley Ann Warren. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002_7.txt</td>\n",
       "      <td>b'This is easily the most underrated film inn ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003_8.txt</td>\n",
       "      <td>b'This is not the typical Mel Brooks film. It ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           file                                               text  \\\n",
       "0       0_9.txt  b'Bromwell High is a cartoon comedy. It ran at...   \n",
       "1   10000_8.txt  b'Homelessness (or Houselessness as George Car...   \n",
       "2  10001_10.txt  b'Brilliant over-acting by Lesley Ann Warren. ...   \n",
       "3   10002_7.txt  b'This is easily the most underrated film inn ...   \n",
       "4   10003_8.txt  b'This is not the typical Mel Brooks film. It ...   \n",
       "\n",
       "   is_positive  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train['text']=new_train['text'].astype(str)\n",
    "new_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-exception",
   "metadata": {},
   "source": [
    "#  Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "strong-acrylic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yunan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "entertaining-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenize import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "digital-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "wpt=nltk.WordPunctTokenizer()\n",
    "stop_words=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eleven-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.casual import casual_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "chicken-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer #  Snowball stemmer > Porter stemmer\n",
    "from nltk.tokenize.casual import casual_tokenize  # we use casual tokenize because this is colloquial text\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words  # sklearn stop words is larger than nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "continuing-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "def decontracted(phrase):\n",
    "    # Taken from https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "    \n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "\n",
    "def tokenize_phrase(text):\n",
    "    phrase = decontracted(text.replace('\\\\', '').replace(\"b'\", \"\")) # remove backslashes and replace contractions\n",
    "    tokens = casual_tokenize(phrase, reduce_len=True, strip_handles=True)\n",
    "    normalized_tokens = [x.lower() for x in tokens] #  convert to all lowercase\n",
    "    filtered_tokens = [x for x in normalized_tokens if x not in sklearn_stop_words] #  filter stop words\n",
    "    filtered_tokens = [x for x in filtered_tokens if x and x not in '- \\t\\n.\"\\':[...][\\\\]()/[br]<>*~,;!?'] #  filter punctuations\n",
    "    stemmed_tokens = [stemmer.stem(w) for w in filtered_tokens] # perform stemming\n",
    "    return stemmed_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "conventional-shaft",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>is_positive</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_9.txt</td>\n",
       "      <td>b'Bromwell High is a cartoon comedy. It ran at...</td>\n",
       "      <td>1</td>\n",
       "      <td>[bromwel, high, cartoon, comedi, ran, time, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000_8.txt</td>\n",
       "      <td>b'Homelessness (or Houselessness as George Car...</td>\n",
       "      <td>1</td>\n",
       "      <td>[homeless, houseless, georg, carlin, state, is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001_10.txt</td>\n",
       "      <td>b'Brilliant over-acting by Lesley Ann Warren. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[brilliant, over-act, lesley, ann, warren, bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002_7.txt</td>\n",
       "      <td>b'This is easily the most underrated film inn ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[easili, underr, film, inn, brook, cannon, sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003_8.txt</td>\n",
       "      <td>b'This is not the typical Mel Brooks film. It ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[typic, mel, brook, film, slapstick, movi, act...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           file                                               text  \\\n",
       "0       0_9.txt  b'Bromwell High is a cartoon comedy. It ran at...   \n",
       "1   10000_8.txt  b'Homelessness (or Houselessness as George Car...   \n",
       "2  10001_10.txt  b'Brilliant over-acting by Lesley Ann Warren. ...   \n",
       "3   10002_7.txt  b'This is easily the most underrated film inn ...   \n",
       "4   10003_8.txt  b'This is not the typical Mel Brooks film. It ...   \n",
       "\n",
       "   is_positive                                             tokens  \n",
       "0            1  [bromwel, high, cartoon, comedi, ran, time, pr...  \n",
       "1            1  [homeless, houseless, georg, carlin, state, is...  \n",
       "2            1  [brilliant, over-act, lesley, ann, warren, bes...  \n",
       "3            1  [easili, underr, film, inn, brook, cannon, sur...  \n",
       "4            1  [typic, mel, brook, film, slapstick, movi, act...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train['tokens'] = new_train['text'].apply(tokenize_phrase)\n",
    "new_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "reasonable-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "geological-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "earned-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(str(new_train['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "stupid-union",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       b'Bromwell High is a cartoon comedy. It ran at...\n",
       "1       b'Homelessness (or Houselessness as George Car...\n",
       "2       b'Brilliant over-acting by Lesley Ann Warren. ...\n",
       "3       b'This is easily the most underrated film inn ...\n",
       "4       b'This is not the typical Mel Brooks film. It ...\n",
       "                              ...                        \n",
       "4995    b\"Towards the end of the movie, I felt it was ...\n",
       "4996    b'This is the kind of movie that my enemies co...\n",
       "4997    b\"I saw 'Descent' last night at the Stockholm ...\n",
       "4998    b\"Some films that you pick up for a pound turn...\n",
       "4999    b\"This is one of the dumbest films, I've ever ...\n",
       "Name: text, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "pacific-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list=[token for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "pediatric-workshop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       "       ,\n",
       " b'Bromwell,\n",
       " High,\n",
       " is,\n",
       " a,\n",
       " cartoon,\n",
       " comedy,\n",
       " .,\n",
       " It,\n",
       " ran,\n",
       " at,\n",
       " ...,\n",
       " ,\n",
       " 1,\n",
       "       ,\n",
       " b'Homelessness,\n",
       " (,\n",
       " or,\n",
       " Houselessness,\n",
       " as,\n",
       " George,\n",
       " Car,\n",
       " ...,\n",
       " ,\n",
       " 2,\n",
       "       ,\n",
       " b'Brilliant,\n",
       " over,\n",
       " -,\n",
       " acting,\n",
       " by,\n",
       " Lesley,\n",
       " Ann,\n",
       " Warren,\n",
       " .,\n",
       " ...,\n",
       " ,\n",
       " 3,\n",
       "       ,\n",
       " b'This,\n",
       " is,\n",
       " easily,\n",
       " the,\n",
       " most,\n",
       " underrated,\n",
       " film,\n",
       " inn,\n",
       " ...,\n",
       " ,\n",
       " 4,\n",
       "       ,\n",
       " b'This,\n",
       " is,\n",
       " not,\n",
       " the,\n",
       " typical,\n",
       " Mel,\n",
       " Brooks,\n",
       " film,\n",
       " .,\n",
       " It,\n",
       " ...,\n",
       " \n",
       "                               ,\n",
       " ...,\n",
       "                        ,\n",
       " 4995,\n",
       "    ,\n",
       " b\"Towards,\n",
       " the,\n",
       " end,\n",
       " of,\n",
       " the,\n",
       " movie,\n",
       " ,,\n",
       " I,\n",
       " felt,\n",
       " it,\n",
       " was,\n",
       " ...,\n",
       " ,\n",
       " 4996,\n",
       "    ,\n",
       " b'This,\n",
       " is,\n",
       " the,\n",
       " kind,\n",
       " of,\n",
       " movie,\n",
       " that,\n",
       " my,\n",
       " enemies,\n",
       " co,\n",
       " ...,\n",
       " ,\n",
       " 4997,\n",
       "    ,\n",
       " b\"I,\n",
       " saw,\n",
       " ',\n",
       " Descent,\n",
       " ',\n",
       " last,\n",
       " night,\n",
       " at,\n",
       " the,\n",
       " Stockholm,\n",
       " ...,\n",
       " ,\n",
       " 4998,\n",
       "    ,\n",
       " b\"Some,\n",
       " films,\n",
       " that,\n",
       " you,\n",
       " pick,\n",
       " up,\n",
       " for,\n",
       " a,\n",
       " pound,\n",
       " turn,\n",
       " ...,\n",
       " ,\n",
       " 4999,\n",
       "    ,\n",
       " b\"This,\n",
       " is,\n",
       " one,\n",
       " of,\n",
       " the,\n",
       " dumbest,\n",
       " films,\n",
       " ,,\n",
       " I,\n",
       " 've,\n",
       " ever,\n",
       " ...,\n",
       " ,\n",
       " Name,\n",
       " :,\n",
       " text,\n",
       " ,,\n",
       " Length,\n",
       " :,\n",
       " 5000,\n",
       " ,,\n",
       " dtype,\n",
       " :,\n",
       " object]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "criminal-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tokens=[token for token in token_list if not token.is_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "radical-devil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       "       ,\n",
       " b'Bromwell,\n",
       " High,\n",
       " cartoon,\n",
       " comedy,\n",
       " .,\n",
       " ran,\n",
       " ...,\n",
       " ,\n",
       " 1,\n",
       "       ,\n",
       " b'Homelessness,\n",
       " (,\n",
       " Houselessness,\n",
       " George,\n",
       " Car,\n",
       " ...,\n",
       " ,\n",
       " 2,\n",
       "       ,\n",
       " b'Brilliant,\n",
       " -,\n",
       " acting,\n",
       " Lesley,\n",
       " Ann,\n",
       " Warren,\n",
       " .,\n",
       " ...,\n",
       " ,\n",
       " 3,\n",
       "       ,\n",
       " b'This,\n",
       " easily,\n",
       " underrated,\n",
       " film,\n",
       " inn,\n",
       " ...,\n",
       " ,\n",
       " 4,\n",
       "       ,\n",
       " b'This,\n",
       " typical,\n",
       " Mel,\n",
       " Brooks,\n",
       " film,\n",
       " .,\n",
       " ...,\n",
       " \n",
       "                               ,\n",
       " ...,\n",
       "                        ,\n",
       " 4995,\n",
       "    ,\n",
       " b\"Towards,\n",
       " end,\n",
       " movie,\n",
       " ,,\n",
       " felt,\n",
       " ...,\n",
       " ,\n",
       " 4996,\n",
       "    ,\n",
       " b'This,\n",
       " kind,\n",
       " movie,\n",
       " enemies,\n",
       " co,\n",
       " ...,\n",
       " ,\n",
       " 4997,\n",
       "    ,\n",
       " b\"I,\n",
       " saw,\n",
       " ',\n",
       " Descent,\n",
       " ',\n",
       " night,\n",
       " Stockholm,\n",
       " ...,\n",
       " ,\n",
       " 4998,\n",
       "    ,\n",
       " b\"Some,\n",
       " films,\n",
       " pick,\n",
       " pound,\n",
       " turn,\n",
       " ...,\n",
       " ,\n",
       " 4999,\n",
       "    ,\n",
       " b\"This,\n",
       " dumbest,\n",
       " films,\n",
       " ,,\n",
       " ...,\n",
       " ,\n",
       " :,\n",
       " text,\n",
       " ,,\n",
       " Length,\n",
       " :,\n",
       " 5000,\n",
       " ,,\n",
       " dtype,\n",
       " :,\n",
       " object]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-flush",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-structure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-money",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_document(doc):\n",
    "    # lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(split):\n",
    "    if split.lower() == 'train':\n",
    "        folder = 'train'\n",
    "    elif split.lower() == 'test':\n",
    "        folder = 'test'\n",
    "    else:\n",
    "        raise ValueError('Invalid data split specified.')\n",
    "        \n",
    "    file_names = []\n",
    "    text = []\n",
    "    is_positive = []\n",
    "    \n",
    "    # read all positive files\n",
    "    files = glob.glob(os.path.join(\"data\", folder, 'pos', '*'))\n",
    "    for file in files:\n",
    "        head, tail = os.path.split(file)\n",
    "        file_names.append(tail)\n",
    "        is_positive.append(1)\n",
    "        with open(file, 'rb') as open_file:\n",
    "            text.append(open_file.readlines()[0])\n",
    "            \n",
    "    # read all negative files\n",
    "    files = glob.glob(os.path.join(\"data\", folder, 'neg', '*'))\n",
    "    for file in files:\n",
    "        head, tail = os.path.split(file)\n",
    "        file_names.append(tail)\n",
    "        is_positive.append(0)\n",
    "        with open(file, 'rb') as open_file:\n",
    "            text.append(open_file.readlines()[0])\n",
    "            \n",
    "    return pd.DataFrame(data={'file': file_names, 'text': text, 'is_positive': is_positive})\n",
    "\n",
    "\n",
    "train_df = get_data('train')\n",
    "train_df['text'] = train_df['text'].astype(str)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-interval",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-ghost",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-confusion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
